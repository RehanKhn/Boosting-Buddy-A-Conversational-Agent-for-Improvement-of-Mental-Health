{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IBDM Movie Review Sentiment Analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP7xJBii9lZASUU+83WbP+p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RehanKhn/Boosting-Buddy-A-Conversational-Agent-for-Improvement-of-Mental-Health/blob/main/IBDM_Movie_Review_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMtYNYxYo9_B"
      },
      "source": [
        "!pip install -U -q PyDrive\r\n",
        "from pydrive.auth import GoogleAuth\r\n",
        "from pydrive.drive import GoogleDrive\r\n",
        "from google.colab import auth\r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "\r\n",
        "from keras.datasets import imdb\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from keras.layers import LSTM, Activation, Dropout, Dense, Input, Conv1D, MaxPooling1D, GlobalMaxPooling1D\r\n",
        "from keras.layers.embeddings import Embedding\r\n",
        "from keras.models import Model\r\n",
        "import string\r\n",
        "import re\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "import keras\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIvgmS83o-wC"
      },
      "source": [
        "auth.authenticate_user()\r\n",
        "gauth = GoogleAuth()\r\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\r\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mwiIrcCph1X"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':'1sTFwYuZ_IyyunrKOeKxH4QCGn7xw0D-d'}) \r\n",
        "downloaded.GetContentFile('reviews.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "MictPrfEqFml",
        "outputId": "a4492950-4190-43a9-9e0f-da037345fb13"
      },
      "source": [
        "data = pd.read_csv(\"reviews.csv\")\r\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am a Catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>No one expects the Star Trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "0      One of the other reviewers has mentioned that ...  positive\n",
              "1      A wonderful little production. <br /><br />The...  positive\n",
              "2      I thought this was a wonderful way to spend ti...  positive\n",
              "3      Basically there's a family where a little boy ...  negative\n",
              "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "...                                                  ...       ...\n",
              "49995  I thought this movie did a down right good job...  positive\n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
              "49997  I am a Catholic taught in parochial elementary...  negative\n",
              "49998  I'm going to have to disagree with the previou...  negative\n",
              "49999  No one expects the Star Trek movies to be high...  negative\n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UiVJ7v6tLWr"
      },
      "source": [
        "data['review'] = data['review'].str.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfLVgy5CUxfm"
      },
      "source": [
        "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \r\n",
        "             \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\",\r\n",
        "             \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \r\n",
        "             \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\",\r\n",
        "             \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\",\r\n",
        "             \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \r\n",
        "             \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\",\r\n",
        "             \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\r\n",
        "             \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\r\n",
        "             \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\r\n",
        "             \"your\", \"yours\", \"yourself\", \"yourselves\" ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efc8axglU7UX"
      },
      "source": [
        "def remove_stopwords(data):\r\n",
        "  data['review without stopwords'] = data['review'].apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords)]))\r\n",
        "  return data\r\n",
        "\r\n",
        "def remove_tags(string):\r\n",
        "    result = re.sub('<.*?>','',string)\r\n",
        "    return result\r\n",
        "    \r\n",
        "data_without_stopwords = remove_stopwords(data)\r\n",
        "data_without_stopwords['clean_review']= data_without_stopwords['review without stopwords'].apply(lambda cw : remove_tags(cw))\r\n",
        "data_without_stopwords['clean_review'] = data_without_stopwords['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEfuNqrpVWbF"
      },
      "source": [
        "reviews_list = []\r\n",
        "reviews = data['review']\r\n",
        "for i in range(len(reviews)):\r\n",
        "  reviews_list.append(reviews[i])\r\n",
        "sentiment = data_without_stopwords['sentiment']\r\n",
        "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, sentiment)))\r\n",
        "\r\n",
        "X_train, X_test,Y_train, Y_test = train_test_split(reviews_list, y, test_size=0.2, random_state = 45)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd0TqKOIVpN3"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\r\n",
        "tokenizer.fit_on_texts(X_train)\r\n",
        "\r\n",
        "words_to_index = tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JsoKLv2gEpK"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':'1QUlCL5MATjZXR8rZrFG4ZvKXXKNOGb5o'}) \r\n",
        "downloaded.GetContentFile('glove6B50d.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91QUFytwYgAG"
      },
      "source": [
        "\r\n",
        "with open(\"glove6B50d.txt\", 'r', encoding='UTF-8') as f:\r\n",
        "  words = set()\r\n",
        "  word_to_vec_map = {}\r\n",
        "  for line in f:\r\n",
        "    w_line = line.split()\r\n",
        "    curr_word = w_line[0]\r\n",
        "    word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\r\n",
        "\r\n",
        "maxLen = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8__Fx9KrZC2t"
      },
      "source": [
        "\r\n",
        "vocab_len = len(words_to_index)\r\n",
        "embed_vector_len = word_to_vec_map['moon'].shape[0]\r\n",
        "\r\n",
        "emb_matrix = np.zeros((vocab_len, embed_vector_len))\r\n",
        "\r\n",
        "for word, index in words_to_index.items():\r\n",
        "  embedding_vector = word_to_vec_map.get(word)\r\n",
        "  if embedding_vector is not None:\r\n",
        "    emb_matrix[index, :] = embedding_vector\r\n",
        "\r\n",
        "embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=maxLen, weights = [emb_matrix], trainable=False)\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBWB1hPCZEy-"
      },
      "source": [
        "def imdb_rating(input_shape):\r\n",
        "\r\n",
        "  X_indices = Input(input_shape)\r\n",
        "\r\n",
        "  embeddings = embedding_layer(X_indices)\r\n",
        "\r\n",
        "  X = LSTM(128, return_sequences=True)(embeddings)\r\n",
        "\r\n",
        "  X = Dropout(0.6)(X)\r\n",
        "\r\n",
        "  X = LSTM(128, return_sequences=True)(X)\r\n",
        "\r\n",
        "  X = Dropout(0.6)(X)\r\n",
        "\r\n",
        "  X = LSTM(128)(X)\r\n",
        "\r\n",
        "  X = Dense(1, activation='sigmoid')(X)\r\n",
        "\r\n",
        "  model = Model(inputs=X_indices, outputs=X)\r\n",
        "\r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt8advKrhUBQ"
      },
      "source": [
        "def conv1d_model(input_shape):\r\n",
        "\r\n",
        "  X_indices = Input(input_shape)\r\n",
        "\r\n",
        "  embeddings = embedding_layer(X_indices)\r\n",
        "\r\n",
        "  X = Conv1D(512,3,activation='relu')(embeddings)\r\n",
        "  \r\n",
        "  X = MaxPooling1D(3)(X)\r\n",
        "\r\n",
        "  X = Conv1D(256,3,activation='relu')(X)\r\n",
        "  \r\n",
        "  X = MaxPooling1D(3)(X)\r\n",
        "\r\n",
        "  X = Conv1D(256,3,activation='relu')(X)\r\n",
        "  X = Dropout(0.8)(X)\r\n",
        "  X = MaxPooling1D(3)(X)\r\n",
        "\r\n",
        "  X = GlobalMaxPooling1D()(X)\r\n",
        "\r\n",
        "  X = Dense(256, activation='relu')(X)\r\n",
        "  X = Dense(1, activation='sigmoid')(X)\r\n",
        "\r\n",
        "  model = Model(inputs=X_indices, outputs=X)\r\n",
        "\r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr5u3fUBhWmL",
        "outputId": "3a08b673-21d4-4b46-ad64-7c71ce1dc876"
      },
      "source": [
        "model = imdb_rating((maxLen,))\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 150)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 150, 50)           5612100   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 150, 128)          91648     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 150, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 150, 128)          131584    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 150, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 5,967,045\n",
            "Trainable params: 354,945\n",
            "Non-trainable params: 5,612,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1AkvIPrhYiM",
        "outputId": "2378545c-04b2-477f-b6e7-f8e51d37ae95"
      },
      "source": [
        "model_1d = conv1d_model((maxLen,))\r\n",
        "model_1d.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 150)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 150, 50)           5612100   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 148, 512)          77312     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 49, 512)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 47, 256)           393472    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 15, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 13, 256)           196864    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 13, 256)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 4, 256)            0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 6,345,797\n",
            "Trainable params: 733,697\n",
            "Non-trainable params: 5,612,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egoQ8yQ4hbsj"
      },
      "source": [
        "X_train_indices = tokenizer.texts_to_sequences(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4_icHa8iF8j",
        "outputId": "bb7057c1-d632-4738-dd6f-9f5042c23fa6"
      },
      "source": [
        "X_train_indices = pad_sequences(X_train_indices, maxlen=maxLen, padding='post')\r\n",
        "X_train_indices.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 150)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-aigsGRiLNA"
      },
      "source": [
        "adam = keras.optimizers.Adam(learning_rate = 0.0001)\r\n",
        "model_1d.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKyQqMENiLq1",
        "outputId": "47f3828c-1c6d-4019-c572-826ed5ae4216"
      },
      "source": [
        "model_1d.fit(X_train_indices, Y_train, batch_size=64, epochs=15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "625/625 [==============================] - 12s 8ms/step - loss: 0.6312 - accuracy: 0.6312\n",
            "Epoch 2/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.4972 - accuracy: 0.7564\n",
            "Epoch 3/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.4489 - accuracy: 0.7895\n",
            "Epoch 4/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.4142 - accuracy: 0.8104\n",
            "Epoch 5/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.3887 - accuracy: 0.8236\n",
            "Epoch 6/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.3697 - accuracy: 0.8343\n",
            "Epoch 7/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.3456 - accuracy: 0.8487\n",
            "Epoch 8/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.3257 - accuracy: 0.8573\n",
            "Epoch 9/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.3000 - accuracy: 0.8712\n",
            "Epoch 10/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.2790 - accuracy: 0.8802\n",
            "Epoch 11/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.2511 - accuracy: 0.8953\n",
            "Epoch 12/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.2310 - accuracy: 0.9057\n",
            "Epoch 13/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.2098 - accuracy: 0.9142\n",
            "Epoch 14/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.1711 - accuracy: 0.9327\n",
            "Epoch 15/15\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.1524 - accuracy: 0.9424\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb4567baba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1gkNL60iOLd"
      },
      "source": [
        "adam = keras.optimizers.Adam(learning_rate = 0.0001)\r\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VSA3fhziRHD",
        "outputId": "c0fafe1f-df5d-4e69-d037-222f3a3a5728"
      },
      "source": [
        "model.fit(X_train_indices, Y_train, batch_size=64, epochs=15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "625/625 [==============================] - 18s 25ms/step - loss: 0.6559 - accuracy: 0.5945\n",
            "Epoch 2/15\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.5310 - accuracy: 0.7380\n",
            "Epoch 3/15\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.4852 - accuracy: 0.7685\n",
            "Epoch 4/15\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.4596 - accuracy: 0.7819\n",
            "Epoch 5/15\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.4436 - accuracy: 0.7949\n",
            "Epoch 6/15\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.4357 - accuracy: 0.7977\n",
            "Epoch 7/15\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.4105 - accuracy: 0.8157\n",
            "Epoch 8/15\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.4144 - accuracy: 0.8085\n",
            "Epoch 9/15\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.3958 - accuracy: 0.8221\n",
            "Epoch 10/15\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.3881 - accuracy: 0.8253\n",
            "Epoch 11/15\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.3806 - accuracy: 0.8299\n",
            "Epoch 12/15\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.3689 - accuracy: 0.8361\n",
            "Epoch 13/15\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.3615 - accuracy: 0.8448\n",
            "Epoch 14/15\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.3657 - accuracy: 0.8382\n",
            "Epoch 15/15\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.3501 - accuracy: 0.8461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb4567d4160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jjyNSxZiTH8"
      },
      "source": [
        "X_test_indices = tokenizer.texts_to_sequences(X_test)\r\n",
        "\r\n",
        "X_test_indices = pad_sequences(X_test_indices, maxlen=maxLen, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tGbaKSYiVMz",
        "outputId": "254d215b-3681-4315-9e1a-d9b96ce50966"
      },
      "source": [
        "model.evaluate(X_test_indices, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 4s 10ms/step - loss: 0.3657 - accuracy: 0.8393\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3656839430332184, 0.8392999768257141]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt0M-Q3KiWoU",
        "outputId": "20546b27-2866-4d4f-9895-46469a6cf319"
      },
      "source": [
        "model_1d.evaluate(X_test_indices, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3794 - accuracy: 0.8344\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.37937217950820923, 0.8343999981880188]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLgTunRjiYAU"
      },
      "source": [
        "preds = model_1d.predict(X_test_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "eBzPPNNyiZgg",
        "outputId": "6a5a8472-0c40-4b05-eb70-e837f3b75196"
      },
      "source": [
        "n = np.random.randint(0,9999)\r\n",
        "\r\n",
        "X_test[n]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'arthur miller has always been known as one of america\\'s great playwrights for works such as \"death of a salesman\" and \"the crucible\". \"focus\" is one of his lesser known plays brought to the silver screen. however, knowing what a great playwright arthur miller is, i doubt that his original play was very much like the movie. the movie comes across as empty and formulaic, with william h. macy as a non-jew mistaken for a jew by anti-semitic neighbors in wwii brooklyn. don\\'t get me wrong: the acting is ok, and i presume that the people behind this movie were probably trying to make a point about racism, but the movie just doesn\\'t work. macy, laura dern and david paymer just can\\'t create an effective story with the material here.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ADRLF4picjg",
        "outputId": "7d0eea81-4770-4b06-f333-9648e646445a"
      },
      "source": [
        "if preds[n] > 0.5:\r\n",
        "  print('predicted sentiment : positive')\r\n",
        "else: \r\n",
        "  print('precicted sentiment : negative')\r\n",
        "\r\n",
        "if (Y_test[n] == 1):\r\n",
        "  print('correct sentiment : positive')\r\n",
        "else:\r\n",
        "  print('correct sentiment : negative')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precicted sentiment : negative\n",
            "correct sentiment : negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXWK8qs9ieX6",
        "outputId": "d8697016-61f4-4d04-95ac-dc4cb02221a6"
      },
      "source": [
        "preds[n]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.46976686], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVuk23mMifyI",
        "outputId": "040fe8c2-5a6c-4e3f-c8ee-66d0d3f9aacc"
      },
      "source": [
        "Y_test[n]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVuGPoGfiss0"
      },
      "source": [
        "reviews_list_idx = tokenizer.texts_to_sequences(reviews_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDopFTMQitBN"
      },
      "source": [
        "def add_score_predictions(data, reviews_list_idx):\r\n",
        "\r\n",
        "  data['sentiment score'] = 0\r\n",
        "\r\n",
        "  reviews_list_idx = pad_sequences(reviews_list_idx, maxlen=maxLen, padding='post')\r\n",
        "\r\n",
        "  review_preds = model.predict(reviews_list_idx)\r\n",
        "\r\n",
        "  data['sentiment score'] = review_preds\r\n",
        "\r\n",
        "  pred_sentiment = np.array(list(map(lambda x : 'positive' if x > 0.5 else 'negative',review_preds)))\r\n",
        "\r\n",
        "  data['predicted sentiment'] = 0\r\n",
        "\r\n",
        "  data['predicted sentiment'] = pred_sentiment\r\n",
        "\r\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naDaoeAriul1"
      },
      "source": [
        "data = add_score_predictions(data, reviews_list_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "6s-LVZbriwTU",
        "outputId": "074fa444-2ae2-46fb-81e4-ad88cd0ee9ec"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review without stopwords</th>\n",
              "      <th>clean_review</th>\n",
              "      <th>sentiment score</th>\n",
              "      <th>predicted sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>one of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>one reviewers mentioned watching just 1 oz epi...</td>\n",
              "      <td>one reviewers mentioned watching just 1 oz epi...</td>\n",
              "      <td>0.785530</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
              "      <td>positive</td>\n",
              "      <td>wonderful little production. &lt;br /&gt;&lt;br /&gt;the f...</td>\n",
              "      <td>wonderful little production  the filming techn...</td>\n",
              "      <td>0.991308</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>thought wonderful way spend time hot summer we...</td>\n",
              "      <td>thought wonderful way spend time hot summer we...</td>\n",
              "      <td>0.834875</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>basically family little boy (jake) thinks zomb...</td>\n",
              "      <td>basically family little boy  jake  thinks zomb...</td>\n",
              "      <td>0.061804</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>petter mattei's \"love time money\" visually stu...</td>\n",
              "      <td>petter mattei s  love time money  visually stu...</td>\n",
              "      <td>0.989072</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>i thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "      <td>thought movie right good job. wasn't creative ...</td>\n",
              "      <td>thought movie right good job  wasn t creative ...</td>\n",
              "      <td>0.952834</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>bad plot  bad dialogue  bad acting  idiotic di...</td>\n",
              "      <td>0.039580</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>i am a catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "      <td>catholic taught parochial elementary schools n...</td>\n",
              "      <td>catholic taught parochial elementary schools n...</td>\n",
              "      <td>0.443552</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>i'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "      <td>going disagree previous comment side maltin on...</td>\n",
              "      <td>going disagree previous comment side maltin on...</td>\n",
              "      <td>0.489558</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>no one expects the star trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "      <td>no one expects star trek movies high art, fans...</td>\n",
              "      <td>no one expects star trek movies high art  fans...</td>\n",
              "      <td>0.024053</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review  ... predicted sentiment\n",
              "0      one of the other reviewers has mentioned that ...  ...            positive\n",
              "1      a wonderful little production. <br /><br />the...  ...            positive\n",
              "2      i thought this was a wonderful way to spend ti...  ...            positive\n",
              "3      basically there's a family where a little boy ...  ...            negative\n",
              "4      petter mattei's \"love in the time of money\" is...  ...            positive\n",
              "...                                                  ...  ...                 ...\n",
              "49995  i thought this movie did a down right good job...  ...            positive\n",
              "49996  bad plot, bad dialogue, bad acting, idiotic di...  ...            negative\n",
              "49997  i am a catholic taught in parochial elementary...  ...            negative\n",
              "49998  i'm going to have to disagree with the previou...  ...            negative\n",
              "49999  no one expects the star trek movies to be high...  ...            negative\n",
              "\n",
              "[50000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    }
  ]
}